{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37721a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-26 09:24:51,186\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2023-11-26 09:24:51,187\tINFO resource_spec.py:216 -- Starting Ray with 32.96 GiB memory available for workers and up to 16.5 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2023-11-26 09:24:51,477\tINFO trainer.py:371 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2023-11-26 09:24:51,480\tINFO trainer.py:512 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2023-11-26 09:24:54,173\tWARNING util.py:45 -- Install gputil for GPU system monitoring.\n",
      "2023-11-26 09:24:54,212\tINFO trainable.py:346 -- Restored from checkpoint: /mnt/c/Users/09_gi/Desktop/Beyond-Simulated-Drivers/intersection/Villarreal_et_al/Trained_policies/PPO_IntersectionRLPOEnv-v0_9a601ff2_2023-11-23_17-35-28q6olyj3t/checkpoint_100/checkpoint-100\n",
      "2023-11-26 09:24:54,212\tINFO trainable.py:353 -- Current state after restoring: {'_iteration': 100, '_timesteps_total': 2500000, '_time_total': 3162.4344210624695, '_episodes_total': 997}\n",
      "Traceback (most recent call last):\n",
      "  File \"test_rllib.py\", line 379, in <module>\n",
      "    visualizer_rllib(args)\n",
      "  File \"test_rllib.py\", line 223, in visualizer_rllib\n",
      "    state, reward, done, _ = env.step(action)\n",
      "  File \"/mnt/c/Users/09_gi/Desktop/Beyond-Simulated-Drivers/flow/envs/base.py\", line 368, in step\n",
      "    self.k.simulation.simulation_step()\n",
      "  File \"/mnt/c/Users/09_gi/Desktop/Beyond-Simulated-Drivers/flow/core/kernel/simulation/traci.py\", line 92, in simulation_step\n",
      "    self.kernel_api.simulationStep()\n",
      "  File \"/home/kurukshetra/anaconda3/envs/flow/lib/python3.7/site-packages/traci/connection.py\", line 323, in simulationStep\n",
      "    result = self._sendExact()\n",
      "  File \"/home/kurukshetra/anaconda3/envs/flow/lib/python3.7/site-packages/traci/connection.py\", line 99, in _sendExact\n",
      "    raise FatalTraCIError(\"connection closed by SUMO\")\n",
      "traci.exceptions.FatalTraCIError: connection closed by SUMO\n"
     ]
    }
   ],
   "source": [
    "!python test_rllib.py /mnt/c/Users/09_gi/Desktop/Beyond-Simulated-Drivers/intersection/Villarreal_et_al/Trained_policies/PPO_IntersectionRLPOEnv-v0_9a601ff2_2023-11-23_17-35-28q6olyj3t 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1b8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: visualizer_rllib.py [-h] [--run RUN] [--num_rollouts NUM_ROLLOUTS]\r\n",
      "                           [--gen_emission] [--evaluate]\r\n",
      "                           [--render_mode RENDER_MODE] [--save_render]\r\n",
      "                           [--horizon HORIZON]\r\n",
      "                           result_dir checkpoint_num\r\n",
      "\r\n",
      "[Flow] Evaluates a reinforcement learning agent given a checkpoint.\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  result_dir            Directory containing results\r\n",
      "  checkpoint_num        Checkpoint number.\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --run RUN             The algorithm or model to train. This may refer to the\r\n",
      "                        name of a built-on algorithm (e.g. RLLib's DQN or\r\n",
      "                        PPO), or a user-defined trainable function or class\r\n",
      "                        registered in the tune registry. Required for results\r\n",
      "                        trained with flow-0.2.0 and before.\r\n",
      "  --num_rollouts NUM_ROLLOUTS\r\n",
      "                        The number of rollouts to visualize.\r\n",
      "  --gen_emission        Specifies whether to generate an emission file from\r\n",
      "                        the simulation\r\n",
      "  --evaluate            Specifies whether to use the 'evaluate' reward for the\r\n",
      "                        environment.\r\n",
      "  --render_mode RENDER_MODE\r\n",
      "                        Pick the render mode. Options include sumo_web3d, rgbd\r\n",
      "                        and sumo_gui\r\n",
      "  --save_render         Saves a rendered video to a file. NOTE: Overrides\r\n",
      "                        render_mode with pyglet rendering.\r\n",
      "  --horizon HORIZON     Specifies the horizon.\r\n",
      "\r\n",
      "example usage:\r\n",
      "    python ./visualizer_rllib.py /ray_results/experiment_dir/result_dir 1\r\n",
      "\r\n",
      "Here the arguments are:\r\n",
      "1 - the path to the simulation results\r\n",
      "2 - the number of the checkpoint\r\n"
     ]
    }
   ],
   "source": [
    "!python visualizer_rllib.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0604ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
