Failure # 1 (occurred at 2023-11-28_07-57-46)
Traceback (most recent call last):
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 426, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 378, in fetch_result
    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/worker.py", line 1457, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RayOutOfMemoryError): [36mray::PPO.train()[39m (pid=1482, ip=172.19.177.241)
  File "python/ray/_raylet.pyx", line 636, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 619, in ray._raylet.execute_task.function_executor
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 444, in train
    raise e
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 433, in train
    result = Trainable.train(self)
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/tune/trainable.py", line 176, in train
    result = self._train()
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 129, in _train
    fetches = self.optimizer.step()
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/optimizers/multi_gpu_optimizer.py", line 140, in step
    self.num_envs_per_worker, self.train_batch_size)
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/optimizers/rollout.py", line 29, in collect_samples
    next_sample = ray_get_and_free(fut_sample)
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/rllib/utils/memory.py", line 33, in ray_get_and_free
    result = ray.get(object_ids)
ray.exceptions.RayTaskError(RayOutOfMemoryError): [36mray::RolloutWorker[39m (pid=1480, ip=172.19.177.241)
  File "python/ray/_raylet.pyx", line 627, in ray._raylet.execute_task
  File "/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/memory_monitor.py", line 130, in raise_if_low_memory
    self.error_threshold))
ray.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node COM2134 is used (29.64 / 31.17 GB). The top 10 memory consumers are:

PID	MEM	COMMAND
1170	12.88GiB	/home/krishna/anaconda3/envs/flow/bin/python /home/krishna/anaconda3/envs/flow/bin/tensorboard --log
2502	0.63GiB	python train.py intersection
1387	0.59GiB	python train.py intersection
1305	0.59GiB	python train.py intersection
2964	0.46GiB	ray::PPO.train()
2017	0.45GiB	ray::PPO.train()
1482	0.44GiB	ray::PPO.train()
2660	0.39GiB	/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/core/src/ray/thirdparty/redis/src/
1425	0.39GiB	/home/krishna/anaconda3/envs/flow/lib/python3.7/site-packages/ray/core/src/ray/thirdparty/redis/src/
902	0.37GiB	/usr/lib/firefox/firefox -contentproc -childID 4 -isForBrowser -prefsLen 28990 -prefMapSize 234334 -

In addition, up to 0.5 GiB of shared memory is currently being used by the Ray object store. You can set the object store size with the `object_store_memory` parameter when starting Ray, and the max Redis size with `redis_max_memory`. Note that Ray assumes all system memory is available for use by workers. If your system has other applications running, you should manually set these memory limits to a lower value.

